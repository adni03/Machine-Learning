{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment 3 - Feed Forward Neural Network\n",
    "###### Author: Rudraksh Kapil - 177154\n",
    "In this notebook the following tasks are accomplished:\n",
    "    1. General definitions and functions for feed forward neural network.\n",
    "    2. Handwritten digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Making Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activation Function\n",
    "We use a sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prediction Function\n",
    "Predicts output given X and weights and returns accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks accuracy\n",
    "def predict(X, y, w1, w2, verbose=True, bias=True):\n",
    "    y_pred = []\n",
    "    \n",
    "    for x in X:\n",
    "        h = sigmoid(x.dot(w1.T))\n",
    "        if (bias):\n",
    "            temp_h = np.append(np.ones(1), h) # becuase we dont want to add a bias term to h itself\n",
    "        else:\n",
    "            temp_h = h\n",
    "        o = sigmoid(temp_h.dot(w2.T))\n",
    "        y_pred.append(o)\n",
    "        \n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    if (verbose):\n",
    "        print('Predictions before thresholding ');\n",
    "        print(y_pred)\n",
    "        \n",
    "    y_pred[y_pred <  0.5] = 0\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    if (verbose):\n",
    "        print(\"Predictions => \\n\")\n",
    "        print(y_pred)\n",
    "    \n",
    "    accuracy = np.mean(np.asarray(y_pred)==y)\n",
    "    if (verbose):\n",
    "        print(f\"Accuracy => {accuracy*100}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Backprop Function\n",
    "We use a two layer network with variable number of input, hidden, and output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X, Y, n_hid, lr = 0.2, w_init=None, n_iters=1, batch=False,bias=True):\n",
    "    if bias:\n",
    "        # append ones col to X\n",
    "        ones_col = np.ones((X.shape[0],1))\n",
    "        X = np.concatenate((ones_col,X), axis=1)\n",
    "    \n",
    "    bias_int = 1 if bias else 0 # add 1 to weigt dimension if bias is needed\n",
    "    # create weights - if no init given, we randomise to v small values\n",
    "    if w_init is not None:\n",
    "        w1 = np.ones((n_hid,X.shape[1])) * w_init\n",
    "        w2 = np.ones((Y.shape[1],n_hid+bias_int)) * w_init\n",
    "    else:\n",
    "        w1 = np.random.randn(n_hid,X.shape[1]) / 10\n",
    "        w2 = np.random.randn(Y.shape[1],n_hid+bias_int) / 10\n",
    "            \n",
    "    history_w1 = []\n",
    "    history_w2 = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # loop over number of iterations\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        \n",
    "        # for each training example \n",
    "        for idx, (x,y) in enumerate(zip(X,Y)):\n",
    "            ### FORWARD PASS\n",
    "            h = sigmoid(x.dot(w1.T))\n",
    "            if bias:\n",
    "                temp_h = np.append(np.ones(1), h) # becuase we dont want to add a bias term to h itself\n",
    "            else:\n",
    "                temp_h = h\n",
    "            o = sigmoid(temp_h.dot(w2.T))\n",
    "            \n",
    "            ### BACKWARD PASS\n",
    "            do = o*(1-o)*(y-o)\n",
    "            dh = h * (1-h) * do.dot(w2[:,bias_int:]) # skip bias dim if it exists\n",
    "            \n",
    "            ### WEIGHT CHANGES\n",
    "            dw2 = lr * do.reshape(-1,1) * temp_h\n",
    "            dw1 = lr * dh.reshape(-1,1) *(x) \n",
    "\n",
    "            # store deltas if batch\n",
    "            if batch == True:\n",
    "                history_w1.append(dw1)\n",
    "                history_w2.append(dw2)\n",
    "            \n",
    "            # otherwise stochastic update -> update here\n",
    "            else:\n",
    "                ### WEIGHT UPDATES\n",
    "                w2 += dw2\n",
    "                w1 += dw1\n",
    "                \n",
    "        # for bacth update -> update here\n",
    "        if batch is True:\n",
    "            w2 += sum(history_w2)\n",
    "            w1 += sum(history_w1)\n",
    "\n",
    "        # Check accuracy while training\n",
    "        accuracies.append(predict(X,y,w1,w2,verbose=True,bias=bias))\n",
    "        \n",
    "    return w1, w2, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Running:\n",
    "Just change values as required up to and including TT, and let the code do the rest B^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 296.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions before thresholding \n",
      "[[0.59564271]\n",
      " [0.60005064]\n",
      " [0.60005353]\n",
      " [0.6042773 ]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n",
      "Predictions before thresholding \n",
      "[[0.58832188]\n",
      " [0.59248564]\n",
      " [0.59249111]\n",
      " [0.59648378]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n",
      "Predictions before thresholding \n",
      "[[0.58149017]\n",
      " [0.58542437]\n",
      " [0.58543213]\n",
      " [0.58920704]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n",
      "Predictions before thresholding \n",
      "[[0.57512928]\n",
      " [0.57884839]\n",
      " [0.57885816]\n",
      " [0.58242866]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n",
      "Predictions before thresholding \n",
      "[[0.56921828]\n",
      " [0.57273644]\n",
      " [0.57274798]\n",
      " [0.57612722]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n",
      "Predictions before thresholding \n",
      "[[0.56373457]\n",
      " [0.56706548]\n",
      " [0.56707857]\n",
      " [0.57027931]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n",
      "Predictions before thresholding \n",
      "[[0.55865458]\n",
      " [0.56181138]\n",
      " [0.56182581]\n",
      " [0.56486039]]\n",
      "Predictions => \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Accuracy => 100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest accuracy => 1.0\n",
      "[[0.19431361 0.19708386 0.19617216]\n",
      " [0.19431361 0.19708386 0.19617216]] [[0.08922505 0.1335444  0.1335444 ]]\n"
     ]
    }
   ],
   "source": [
    "w_init = 0.2                 # number of hidden units\n",
    "n_hid = 2                    # number of hidden units\n",
    "lr = 0.2                    # learning rate\n",
    "n_iters = 7                  # number of iterations / epochs\n",
    "batch = False                 # if true, algo uses batch update.\n",
    "TT = np.asarray([[0,0,1],    # Truth table\n",
    "                [0,1,0], \n",
    "                [1,0,0],\n",
    "                [1,1,1]])\n",
    "\n",
    "\n",
    "X = TT[:,:2]\n",
    "y = TT[:,2:]\n",
    "w1,w2,accuracies = backprop(X,y,n_hid,lr,w_init,n_iters,batch)\n",
    "\n",
    "# print highest accuracy and display history\n",
    "epochs = np.arange(1, len(accuracies)+1)\n",
    "plt.plot(epochs, accuracies, c='purple')\n",
    "plt.title('Accuracy History')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "print(f\"Highest accuracy => {max(accuracies)}\")\n",
    "\n",
    "print(w1,w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handwritten digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get digits from MNIST Dataset \n",
    "We also show some images for visualisation. The data is loaded directly from keras.datasets becuase the actual files are too large to download and reupload during submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-64ea12c60067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# reduce sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reduce sizes\n",
    "num_train = 1000\n",
    "num_test = 100\n",
    "\n",
    "X_train = X_train[:num_train]\n",
    "Y_train = Y_train[:num_train]\n",
    "X_test = X_test[:num_test]\n",
    "Y_test = Y_test[:num_test]\n",
    "\n",
    "# Convert y vectors to one hot vectors for our network to work\n",
    "Y_train_OH = np.zeros((Y_train.size, Y_train.max()+1))\n",
    "Y_train_OH[np.arange(Y_train.size),Y_train] = 1\n",
    "\n",
    "Y_test_OH = np.zeros((Y_test.size, Y_test.max()+1))\n",
    "Y_test_OH[np.arange(Y_test.size),Y_test] = 1\n",
    "\n",
    "# flatten X and bring into [0,1] range\n",
    "X_train = X_train.reshape(X_train.shape[0],-1) / 255\n",
    "X_test = X_test.reshape(X_test.shape[0],-1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise:\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.axis('off')\n",
    "    r = np.random.randint(X_train.shape[0])   # get a random image to show\n",
    "    plt.title('True Label: '+str(Y_train[r])) # show its label as title\n",
    "    plt.imshow(X_train[r].reshape(28,28), cmap='inferno')    # plot the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here you can see it overfits:\n",
    "w_init = None                 # number of hidden units\n",
    "n_hid = 3                    # number of hidden units\n",
    "lr = 0.01                     # learning rate\n",
    "n_iters = 100                  # number of iterations / epochs\n",
    "batch = False                   # if true, algo uses batch update.\n",
    "bias = True                   # dont add bias dimension\n",
    "\n",
    "\n",
    "w1,w2,accuracies = backprop(X_train,Y_train_OH,n_hid,lr,w_init,n_iters,batch,bias)\n",
    "\n",
    "# print highest accuracy and display history\n",
    "epochs = np.arange(1, len(accuracies)+1)\n",
    "plt.plot(epochs, accuracies, c='purple')\n",
    "plt.title('Accuracy History')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "print(f\"Highest accuracy => {max(accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here you can see it overfits to training data because of 100 hidden units:\n",
    "\n",
    "\n",
    "w_init = None                 # number of hidden units\n",
    "n_hid = 100                    # number of hidden units\n",
    "lr = 0.2                    # learning rate\n",
    "n_iters = 100                  # number of iterations / epochs\n",
    "batch = False                   # if true, algo uses batch update.\n",
    "bias = False                   # dont add bias dimension\n",
    "\n",
    "\n",
    "w1,w2,accuracies = backprop(X_train,Y_train_OH,n_hid,lr,w_init,n_iters,batch,bias)\n",
    "\n",
    "# print highest accuracy and display history\n",
    "epochs = np.arange(1, len(accuracies)+1)\n",
    "plt.plot(epochs, accuracies, c='purple')\n",
    "plt.title('Accuracy History')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "print(f\"Highest accuracy => {max(accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <center> END OF ASSIGNMENT <br><br> Author: Rudraksh Kapil - 177154 <br><br> Thanks for reading :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
